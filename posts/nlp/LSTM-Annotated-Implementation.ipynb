{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc8b3be-c508-4214-b92f-4b1953ccdc52",
   "metadata": {},
   "source": [
    "---\n",
    "title: LSTM Annotated Implementation\n",
    "date: 2023-02-10\n",
    "image: lstm-cell.jpeg\n",
    "categories: [NLP, Deep Learning]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc0f79-2c2d-4414-a7ef-a9e14979e10d",
   "metadata": {},
   "source": [
    "![](lstm-cell.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222deb61-3c15-4332-b520-deace9993706",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e50dc-9f6a-4add-91e2-2cbe002737d8",
   "metadata": {},
   "source": [
    "**Long Short-Term Memory (LSTM)** is an a recurrent neural network (RNN) architectute that was introduced by [Hochreiter and Schmidhuber](https://www.bioinf.jku.at/publications/older/2604.pdf) in 1997 to solve the problem of vanishing gradients that RNNs suffered from for long sequences. This issue is the result of repeated multiplication using the same weights in all timesteps since the weights are shared between all timesteps. Instead of having one hidden state as is the case for RNNs, we have two hidden states: cell state that is responsible for retaining long short-term memory, and hidden state that is focused on predicting the next word.\n",
    "\n",
    "RNNs and LSTMs are **sequential models**, which means they can only take one input at a time to produce one output because the output at time *t* depends not only on $x_t$ but also on the hidden state(s) from $t -1$. This means, we can't parallelize the forward pass and need iterate over all the timesteps to get all the results.\n",
    "\n",
    "In this post, we will focus on implementing LSTM from scratch and compare it with [pytorch](https://pytorch.org/) to check our implementation. Along the way, we will consider performance issues and some ways to optimize our implementation. Hopefully this will help use better understand LSTMs, since the only way to really understand something is to build it yourself from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc520c7-0d9b-4e0c-ae9a-408390709db1",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942060ad-4f7b-4886-a2cf-d8444639fec2",
   "metadata": {},
   "source": [
    "Let's first cover ,at a high level, how LSTM works:\n",
    "\n",
    "- On each timestep *t*, there would be two states: a hidden state $h()$ and a cell state $c()$\n",
    "- Both are vectors length $n$ â€¢ The cell stores long-term information\n",
    "- The LSTM can read, erase, and write information from the cell. Therefore, the cell becomes more like a RAM\n",
    "\n",
    "LSTM solves the vanishing/exploding gradients problems by making it easier to preserve information through longer timesteps.\n",
    "\n",
    "We will first start with implementing `LSTMCell` that operates on 1 input at a time. Next, we will implement `LSTM` module that wraps the `LSTMCell` to work on sequence of inputs and, optionally, stack multiple layers on top of each other to increase the capacity of the model with some regularization using `dropout`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378981c-4c59-4a2d-9fef-b69eefa88fca",
   "metadata": {},
   "source": [
    "## LSTM Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861c9ce-4adf-43d4-99fb-9ec1e1cbd969",
   "metadata": {},
   "source": [
    "Let's take a look at the equations for an `LSTMCell` (each gate has the same dimension as hidden state):\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
    "f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
    "g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
    "o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
    "h_t = o_t \\odot \\tanh(c_t) \\\\\n",
    "\\end{array}\n",
    "\n",
    "Where:\n",
    "\n",
    "- $i_t$ is the input gate. It looks at $x_t$ and $h_t$ and determines what information to keep an what to throw away. The output is between 0 & 1 where 1 means keep all the information and 0 means get rid of this information.\n",
    "- $f_t$ is the forget gate. This gate is responsible to determine which information from the old cell state need to be forgotten in order to be replaced with new information when updating the new cell state based on the input gate.\n",
    "- $g_t$ is the cell gate. This gate determines which cell elements to update with new input data.\n",
    "- $o_t$ is the output gate. This is the last gate which determines which information from cell state to use to output to the new hidden state.\n",
    "\n",
    "Even though we have 4 gates, we actually implement them using one matrix speed up the computation. Then later we will split the output to compute the corresponding gates.\n",
    "\n",
    "Let's implement `LSTMCell` and check its correctness with pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6d3f4a-8fa8-4e2b-938b-9439afa010cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f325555-fdab-47c3-94a6-38a4a2e6dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7aa6509-79db-4a54-9d47-e8c656fa28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long version\n",
    "class LSTMCellNew(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz, bias=True):\n",
    "        super().__init__()\n",
    "        self.weight_ih = nn.Parameter(torch.randn((input_sz, hidden_sz * 4)))\n",
    "        self.weight_hh = nn.Parameter(torch.randn((hidden_sz, hidden_sz * 4)))\n",
    "        self.bias_ih = nn.Parameter(torch.zeros(hidden_sz * 4))\n",
    "        self.bias_hh = nn.Parameter(torch.zeros(hidden_sz * 4))\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        # T x B x hidden_sz\n",
    "        out = x @ self.weight_ih + h @ self.weight_hh + self.bias_ih + self.bias_hh\n",
    "        i, f, g, o = torch.split(out, 100, dim=-1)\n",
    "        i, f, o = torch.sigmoid(i), torch.sigmoid(f), torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        c_t = f * c + i * g\n",
    "        h_t = o * torch.tanh(c_t)\n",
    "        return h_t, c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5630f35-d6a3-435a-8a8d-0ae5c2b87601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short version utilizing linear layer module\n",
    "class LSTMCellNew(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz, bias=True):\n",
    "        super().__init__()\n",
    "        self.ih = nn.Linear(input_sz, hidden_sz * 4, bias=bias)\n",
    "        self.hh = nn.Linear(hidden_sz, hidden_sz * 4, bias=bias)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        out = self.ih(x) + self.hh(h)\n",
    "        i, f, g, o = torch.split(out, 100, dim=-1)\n",
    "        i, f, o = torch.sigmoid(i), torch.sigmoid(f), torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        c_t = f * c + i * g\n",
    "        h_t = o * torch.tanh(c_t)\n",
    "        return h_t, c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9e3a64-ba74-4c22-84ad-77d212fe2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "seq_len = 8\n",
    "input_sz = 20\n",
    "hidden_sz = 100\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f4dcb4-49b0-4f90-bf15-961483ed0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(seq_len, batch_sz, input_sz, dtype=torch.float32)\n",
    "c_0 = torch.randn(num_layers, batch_sz, hidden_sz, dtype=torch.float32)\n",
    "h_0 = torch.randn(num_layers, batch_sz, hidden_sz, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13915d7b-7746-480b-8bfe-85d2000c21a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([400, 100]),\n",
       " torch.Size([400, 20]),\n",
       " torch.Size([400]),\n",
       " torch.Size([400]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_cell = nn.LSTMCell(input_sz, hidden_sz, bias=True)\n",
    "(\n",
    "    pytorch_cell.weight_hh.shape,\n",
    "    pytorch_cell.weight_ih.shape,\n",
    "    pytorch_cell.bias_ih.shape,\n",
    "    pytorch_cell.bias_hh.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dbbe52-f7c4-4dff-9361-6757dffbd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h: B x hidden_sz\n",
    "# c: B x hidden_sz\n",
    "pytorch_h, pytorch_c = pytorch_cell(X[0], (h_0[0], c_0[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7dd706-59f6-4162-b00c-8c3610c573d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = LSTMCellNew(input_sz, hidden_sz)\n",
    "\n",
    "# To make sure pytorch and our implementation both\n",
    "# have the same weights so we can compare them\n",
    "cell.ih.weight.data = pytorch_cell.weight_ih.data\n",
    "cell.hh.weight.data = pytorch_cell.weight_hh.data\n",
    "cell.ih.bias.data = pytorch_cell.bias_ih.data\n",
    "cell.hh.bias.data = pytorch_cell.bias_hh.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a03238d-994b-427e-92bd-7fb1abff8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t, c_t = cell(X[0], h_0[0], c_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bc1356c-0d3e-4e79-a174-0b717407882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.linalg.norm(pytorch_h.detach().numpy() - h_t.detach().numpy()),\n",
    "    np.linalg.norm(pytorch_c.detach().numpy() - c_t.detach().numpy()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa85f57d-f2c7-4175-aeac-e0323e7071ef",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed625679-2547-4974-a0f5-c997b6fd3fb6",
   "metadata": {},
   "source": [
    "There few things worth mentioning about our `LSTM` implementations as well as other implementations in common libraries:\n",
    "\n",
    "- We use sequence length as the first dimension instead of the batch first. This would give us better performance since we iterate over timesteps and we want to avoid copying memory for each operation which would be the case if the matrix is not contiguous when first dimension is the batch. Therefore, we use `T x B x input_sz`.\n",
    "- **Backpropagation Through Time (BPTT)**: This essentially means we backpropagate through all the history for each example when we calculate the gradient of the loss w.r.t. weights. Since for each layer, the weights are shared among all timesteps, long sequences will suffer greatly from vanishing/exploding gradients. Therefore, we typically truncate history by detaching hidden and cell states from computation graph after every batch so gradients stop at $t_0$ for each bach for each sequence. We only have access to the hidden/cell states from previous batch for the same sequence but can't propagate beyond the first timestep of each batch.\n",
    "- We can stack RNNs and LSTMs on top of each other using `num_layers` argument. This would build multiple LSTM layers, each has its own `LSTMCell` that is shared across all timesteps within each layer. This would increase the capacity of the model.\n",
    "- When we have multilpe layers, we can either 1) iterate first over all timesteps for each layer before moving to the next layer Or 2) iterate over number of layers first for a given timestep before moving to the next timestep.\n",
    "- When we have long sequences, it is common that we divide the sequences into shorter segments using predefined block_size.\n",
    "- Since not all sequences have the same length, we need to make them of the same length to utilize matrix-matrix multiplication. There are two approaches to handle this issue:\n",
    "    1. Make the sequence length the length of the longest sequence. Pad shorter sequences with zeros, using either pre-padding (zeros at the beginning) or post-padding (zeros after last token at the end).\n",
    "    2. Padding leads to wasteful computation. To avoid this issue, we can use packed sequences where we combine all sequences together and have indices of where each sequence starts and ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7691b4e-235e-434c-b22f-a5130c6ad864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNew(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz, num_layers=1):\n",
    "        super().__init__()\n",
    "        # self.cell = LSTMCellNew(input_sz, hidden_sz)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_sz = hidden_sz\n",
    "        self.cells = nn.ModuleList(\n",
    "            [\n",
    "                LSTMCellNew(input_sz, hidden_sz)\n",
    "                if i == 0\n",
    "                else LSTMCellNew(hidden_sz, hidden_sz)\n",
    "                for i in range(self.num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h_t, c_t):\n",
    "        # x  :      T     x B x hidden_sz\n",
    "        # h_t: num_layers x B x hidden_sz\n",
    "        # c_t: num_layers x B x hidden_sz\n",
    "        T, B, _ = x.shape\n",
    "        H = torch.zeros(T, B, self.hidden_sz)\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            h, c = h_t[i], c_t[i]\n",
    "            if i > 0:\n",
    "                x = H\n",
    "            for t in range(T):\n",
    "                h, c = cell(x[t], h, c)\n",
    "                H[t] = h\n",
    "            # last hidden state for each layer\n",
    "            h_t[i], c_t[i] = h, c\n",
    "        # Truncated BPTT\n",
    "        return H, (h_t.detach(), c_t.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c608d9-11f0-49a6-bcbf-e8a7387cb205",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_lstm = nn.LSTM(input_sz, hidden_sz, num_layers=num_layers)\n",
    "pytorch_H, (pytorch_h, pytorch_c) = pytorch_lstm(X, (h_0, c_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0966232f-132c-4e2f-b97c-8fa2fab3ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMNew(input_sz, hidden_sz, num_layers=num_layers)\n",
    "\n",
    "for i in range(num_layers):\n",
    "    lstm.cells[i].ih.weight.data = getattr(pytorch_lstm, f\"weight_ih_l{i}\").data\n",
    "    lstm.cells[i].hh.weight.data = getattr(pytorch_lstm, f\"weight_hh_l{i}\").data\n",
    "    lstm.cells[i].ih.bias.data = getattr(pytorch_lstm, f\"bias_ih_l{i}\").data\n",
    "    lstm.cells[i].hh.bias.data = getattr(pytorch_lstm, f\"bias_hh_l{i}\").data\n",
    "\n",
    "H, (h_t, c_t) = lstm(X, h_0, c_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652fc3bb-7371-489b-85c4-8cd2e97fd60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6524093e-07 2.3566642e-07 4.6639343e-07\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.linalg.norm(pytorch_H.detach().numpy() - H.detach().numpy()),\n",
    "    np.linalg.norm(pytorch_h.detach().numpy() - h_t.detach().numpy()),\n",
    "    np.linalg.norm(pytorch_c.detach().numpy() - c_t.detach().numpy()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f253e0-2461-447b-92e4-aea2ab1f2de2",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f12df-fdae-46b3-8a32-02a21cc784e8",
   "metadata": {},
   "source": [
    "LSTMs were for a long time the solution for vanishing/exploding gradients problems vanialla RNNs have. They were the backbone models used in many NLP tasks such as machine translation and classification. In this post, we implemented both LSTM and LSTMCell. Hopefully, working through the implementation step by step made it a little easier and less intimidating to understand it.\n",
    "\n",
    "The key takeaways are:\n",
    "\n",
    "1. RNNs and LSTMs are sequential models. They iteratively go through tokens in the sequence, or batch of sequences, one token at a time to predict the next word. Therefore, we can't parallelize them as we do with FNNs or CNNs.\n",
    "2. Each timestep within the same layer shares the same weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

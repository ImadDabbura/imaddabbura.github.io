{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a8df91-0b76-4abe-a256-ca7df2fd17dd",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Airflow Part 2 - DAGs\"\n",
    "date: \"2022-01-17\"\n",
    "image: feature.png\n",
    "categories: [\"Data Engineering\", \"MLOps\", \"Airflow\"]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48243cb5-f66b-4d0c-9dc3-fb567d6cc643",
   "metadata": {},
   "source": [
    "![](feature.png){fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932b2d9-93fb-4294-9f4d-ab4ba6c89848",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Other than my experience and the documentation, the main resource behind this post and figures is the fantastic book :[_Data Pipelines with Apache. Airflow](https://www.manning.com/books/data-pipelines-with-apache-airflow).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74902c-0362-42da-9c40-930c74eb6d99",
   "metadata": {},
   "source": [
    "- `DAG()` class is needed to instantiate a **DAG** which will be the starting point of any workflow.\n",
    "    - The required arguments are: `dag_id` which is the name Airflow web UI uses to display workflow. `start_date` which is when to start running the workflow, it can be in the past\n",
    "    - There are other arguments such as `schedule_interval` which determines the schedule to rerun the DAG\n",
    "- `Operator` is responsible for a piece of work and almost represents a task.\n",
    "    - It has `task_id` which is the name web UI uses to display the task\n",
    "    - There are many operators such as `BashOperator`, `PythonOperator` ... All of them inherits from `BaseOperator`\n",
    "    - Some operators are generic such as `BashOperator` and some are specific such as `EmailOperator`\n",
    "- `Task` is a wrapper/manager over operator that makes sure the operator gets executed\n",
    "- `>>` represents the dependencies between tasks\n",
    "    - `a` >> `b` means `a` should run before `b`\n",
    "- Airflow UI offers two views:\n",
    "    - **tree view** that shows the DAG runs over time. Each column is one run. Each row is a task. So we can inspect status of tasks over time\n",
    "    - **graph view** that shows the DAG as a graph which helps showing the dependencies of tasks in the workflow\n",
    "- If any task failed, all successive tasks that depend on it don't run\n",
    "    - We can rerun the failed tasks (which also would cause successive tasks to rerun) w/o having to rerun the workflow from scratch\n",
    "    - We can inspect the logs to see what was the reason for the errors\n",
    "- Tasks can run in parallel depending on their dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae909111-6107-43af-b84a-c68eb1e2deff",
   "metadata": {},
   "source": [
    "- To setup Airflow locally inside Python virtual env:\n",
    "    - pip install apache-airflow\n",
    "    - airflow init db # Initialize metastore locally using SQLite; not recommended for production\n",
    "    - airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.org # Create user\n",
    "    - airflow webserver # Start web server to use web UI\n",
    "    - airflow scheduler # Start scheduler, don't use sequential in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135db21e-c3ef-4364-9499-af045aa09635",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): python>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import airflow\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "from airflow.operators.python import PythonOperator\n",
    "\n",
    "f = lambda: print(1)\n",
    "dag = DAG(dag_id=\"simple-workflow\", start_date=airflow.utils.dates.days_ago(10))\n",
    "a = BashOperator(task_id=\"bash\", bash_command=\"echo 'a'\", dag=dag)\n",
    "b = PythonOperator(task_id=\"python\", python_callable=f, dag=dag)\n",
    "a >> b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
